{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---- Statistical decision making by Mrunal Bokil ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data understanding and goal\n",
    "\n",
    "#### Data description :\n",
    "\n",
    "#### Goal : \n",
    "\n",
    "    1.\n",
    "    2.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps involved to analyze the data and reach our goal:\n",
    "\n",
    "    1. Data loading (loading the files)\n",
    "    2. Data handling (remove missing values, remove the extra words at the end of the numeric words)\n",
    "    3. Descriptive statistics (target vs )\n",
    "    4. Data modeling (Apply ML algorithms such as decision tree, random forest, linear regression)\n",
    "    5. Estimation and performance (r^2, rmse, roc?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Dataset and dataframes used are exemplary meaning that the code in each cell may not run but syntax and flow can be reused in other projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_file = pd.read_csv(\"Admission_Predict.csv\")\n",
    "grad_file.head()\n",
    "grad_file.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file_app = data_file_app[data_file_app.Reviews.apply(lambda x: x.isnumeric())]\n",
    "data_file_app['Reviews'] = data_file_app.Reviews.astype(int)\n",
    "\n",
    "data_file_app['Installs'] = data_file_app['Installs'].apply(lambda x: x.replace('+', '') if '+' in str(x) else x)\n",
    "data_file_app['Installs'] = data_file_app['Installs'].apply(lambda x: x.replace(',', '') if ',' in str(x) else x)\n",
    "data_file_app['Installs'] = data_file_app['Installs'].apply(lambda x: int(x))\n",
    "data_file_app['Installs'] = data_file_app['Installs'].apply(lambda x: float(x)) \n",
    "\n",
    "data_file_app['Size'] = data_file_app['Size'].apply(lambda x: str(x).replace('+', '') if '+' in str(x) else x)\n",
    "data_file_app['Size'] = data_file_app['Size'].apply(lambda x: str(x).replace(',', '') if ',' in str(x) else x)\n",
    "data_file_app['Size'] = data_file_app['Size'].apply(lambda x: str(x).replace('M', '') if 'M' in str(x) else x)\n",
    "data_file_app['Size'] = data_file_app['Size'].apply(lambda x: str(x).replace('k', '') if 'k' in str(x) else x)\n",
    "data_file_app['Size'] = data_file_app['Size'].apply(lambda x: str(x).replace('Varies with device', 'NaN') if 'Varies with device' in str(x) else x)\n",
    "#data_file_app['Size'] = data_file_app['Size'].apply(lambda x: int(x))\n",
    "data_file_app['Size'] = data_file_app['Size'].apply(lambda x: float(x)) \n",
    "\n",
    "#what is the size of the most of the apps\n",
    "print(\"Size of the apps: \", data_file_app['Size'].mode())\n",
    "print(\"Maximum size of the apps: \", data_file_app['Size'].max())\n",
    "\n",
    "data_file_app['Price'] = data_file_app['Price'].apply(lambda x: x.replace('$', '') if '$' in str(x) else x)\n",
    "#data_file_app['Price'] = data_file_app['Price'].apply(lambda x: int(x))\n",
    "data_file_app['Price'] = data_file_app['Price'].apply(lambda x: float(x)) \n",
    "\n",
    "data_file_app['Rating'] = data_file_app['Rating'].apply(lambda x: float(x) < 5)\n",
    "#data_file_app['Price'] = data_file_app['Price'].apply(lambda x: int(x))\n",
    "data_file_app['Rating'] = data_file_app['Rating'].apply(lambda x: float(x)) \n",
    "data_file_app.head()\n",
    "\n",
    "data_file_app['Reviews'] = data_file_app.Reviews.astype(int)\n",
    "data_file_app['Price'] = data_file_app.Price.astype(object)\n",
    "data_file_app['Size'] = data_file_app.Size.dropna().astype(int)\n",
    "data_file_app['Installs'] = data_file_app.Installs.astype(int)\n",
    "\n",
    "data_file_app.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# correlation plot\n",
    "\n",
    "grad_file_corr = grad_file.drop('Serial No.', 1).corr()\n",
    "print(grad_file_corr)\n",
    "sns.heatmap(grad_file_corr, xticklabels = grad_file_corr.columns, yticklabels = grad_file_corr.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# countplot (usually for target)\n",
    "\n",
    "sns.countplot(x=\"Type\",data=data_file_app)\n",
    "plt.title('Overall Paid vs free apps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bar graph\n",
    "\n",
    "#data prep\n",
    "data_file_app1 = data_file_app[data_file_app['Type']=='Paid']\n",
    "number_of_apps_in_category_typ = data_file_app1['Category'].value_counts().sort_values(ascending=False)\n",
    "number_of_apps_in_category_typ = number_of_apps_in_category_typ.reset_index()\n",
    "number_of_apps_in_category_typ.columns = [\"Category\",\"Count_cat\"]\n",
    "number_of_apps_in_category_typ['perc'] = (number_of_apps_in_category_typ['Count_cat']/number_of_apps_in_category_typ['Count_cat'].sum())*100\n",
    "number_of_apps_in_category_typ.head(5)\n",
    "\n",
    "#plotting the bar graph\n",
    "plt.figure(figsize=(10,5))\n",
    "index = np.arange(len(number_of_apps_in_category.Category)) # x-axis\n",
    "plt.bar(index, number_of_apps_in_category.Count_cat) # y-axis\n",
    "plt.xlabel('Category', fontsize=12)\n",
    "plt.ylabel('No. of apps', fontsize=12)\n",
    "plt.xticks(index, number_of_apps_in_category.Category, fontsize=12, rotation=80)\n",
    "plt.title('Number of apps per category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# histogram for gre scores to see what is average GRE score across the data\n",
    "\n",
    "#grad_file.columns\n",
    "\n",
    "# first type\n",
    "sns.distplot(grad_file['GRE Score'])\n",
    "plt.show()\n",
    "\n",
    "# second type\n",
    "grad_file.hist(column = 'GRE Score')\n",
    "plt.show()\n",
    "\n",
    "# histogram of all variables together\n",
    "grad_file.drop('Serial No.', 1).hist(bins = 30, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# describe \n",
    "\n",
    "grad_file.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale the data and calcuate one-way ANOVA to see if there is difference between the means\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(grad_file)\n",
    "df_normalized = pd.DataFrame(np_scaled)\n",
    "df_normalized.columns = ['Serial No.', 'GRE Score','TOEFL Score','University Rating', 'SOP', 'LOR','CGPA','Research','Chance_admit']\n",
    "#df_normalized.head()\n",
    "stats.f_oneway(df_normalized['GRE Score'], df_normalized['TOEFL Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variance Inflation factor\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "all_input_var = [\"GRE Score\", \"TOEFL Score\", \"University Rating\", \"SOP\", \"CGPA\", \"Research\"]\n",
    "vif = pd.DataFrame()\n",
    "vif[\"features\"] = grad_file[all_input_var].columns\n",
    "vif[\"vif_score\"] = [variance_inflation_factor(grad_file[all_input_var].values, i) for i in range(grad_file[all_input_var].shape[1])]\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert bianry variable to dummies using get_dummies\n",
    "\n",
    "grad_file.head()\n",
    "X = grad_file[['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'CGPA', 'Research']]\n",
    "Y = grad_file[grad_file.columns[8]]\n",
    "Y.rename(columns = {'Chance of Admit':'admit_score'}, inplace = True)\n",
    "rsrch = pd.get_dummies(grad_file.Research, prefix = 'rsrch')\n",
    "X = pd.concat([X, rsrch], axis=1)\n",
    "drops = ['Research']\n",
    "X.drop(drops, inplace=True, axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recursive feature elimination\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "linreg = LinearRegression()\n",
    "# create the RFE model for the svm classifier \n",
    "# and select attributes\n",
    "rfe = RFE(linreg, 4)\n",
    "rfe = rfe.fit(grad_file[['GRE Score', 'University Rating', 'SOP', 'CGPA', 'Research']], Y)\n",
    "# print summaries for the selection of attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LASSO for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data to training and testing\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all ML algorithm libraries\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn import tree \n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "print('Linear Regression R squared: %.4f' % regressor.score(X_test, y_test))\n",
    "\n",
    "lin_mse = mean_squared_error(y_pred, y_test)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print('Linear Regression RMSE: %.4f' % lin_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomforest\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "forest_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = forest_reg.predict(X_test)\n",
    "forest_mse = mean_squared_error(y_pred, y_test)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print('Random Forest RMSE: %.4f' % forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomforest with Grid Search\n",
    "\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "#from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_1 = { 'bootstrap': [True],\n",
    "           'max_depth': [80, 90, 100, 110],\n",
    "        'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "   'min_samples_split': [8, 10, 12],\n",
    "        'n_estimators': [100, 200, 300, 1000]\n",
    "           }\n",
    "rf = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(rf, param_grid = grid_1, n_jobs=-1, cv=5)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfreg1 = RandomForestRegressor(bootstrap= True, max_depth= 100, max_features= 2, min_samples_leaf= 3, min_samples_split= 10,\n",
    "                               n_estimators= 100)\n",
    "rfreg1.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = rfreg1.predict(X_test)\n",
    "print('Linear Regression R squared: %.4f' % rfreg1.score(X_test, y_test))\n",
    "\n",
    "y_pred = rfreg1.predict(X_test)\n",
    "rfreg1_mse = mean_squared_error(y_pred, y_test)\n",
    "rfreg1_rmse = np.sqrt(rfreg1_mse)\n",
    "print('Random Forest RMSE: %.4f' % rfreg1_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GBM\n",
    "\n",
    "model = ensemble.GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('Gradient Boosting R squared: %.4f' % model.score(X_test, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "model_mse = mean_squared_error(y_pred, y_test)\n",
    "model_rmse = np.sqrt(model_mse)\n",
    "print('Gradient Boosting RMSE: %.4f' % model_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "\n",
    "model = tree.DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('Decision tree R squared: %.4f' % model.score(X_test, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "model_mse = mean_squared_error(y_pred, y_test)\n",
    "model_rmse = np.sqrt(model_mse)\n",
    "print('Decision Tree RMSE: %.4f' % model_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using lasso regression \n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train,y_train)\n",
    "\n",
    "train_score=lasso.score(X_train,y_train)\n",
    "test_score=lasso.score(X_test,y_test)\n",
    "\n",
    "coeff_used = np.sum(lasso.coef_!=0)\n",
    "print(\"training score:\", train_score) \n",
    "print(\"test score: \", test_score)\n",
    "print(\"number of features used: \", coeff_used)\n",
    "#lasso001 = Lasso(alpha=0.01, max_iter=10e5)\n",
    "#lasso001.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alpha = 0.01\n",
    "lasso001 = Lasso(alpha=0.01, max_iter=10e5)\n",
    "lasso001.fit(X_train,y_train)\n",
    "\n",
    "train_score001=lasso001.score(X_train,y_train)\n",
    "test_score001=lasso001.score(X_test,y_test)\n",
    "\n",
    "coeff_used001 = np.sum(lasso001.coef_!=0)\n",
    "\n",
    "print(\"training score for alpha=0.01:\", train_score001) \n",
    "print(\"test score for alpha =0.01: \", test_score001)\n",
    "print(\"number of features used: for alpha =0.01:\", coeff_used001)\n",
    "\n",
    "# alpha = 0.0001\n",
    "lasso00001 = Lasso(alpha=0.0001, max_iter=10e5)\n",
    "lasso00001.fit(X_train,y_train)\n",
    "\n",
    "train_score00001=lasso00001.score(X_train,y_train)\n",
    "test_score00001=lasso00001.score(X_test,y_test)\n",
    "\n",
    "coeff_used00001 = np.sum(lasso00001.coef_!=0)\n",
    "\n",
    "print(\"training score for alpha=0.0001:\", train_score00001) \n",
    "print(\"test score for alpha =0.0001: \", test_score00001)\n",
    "print(\"number of features used: for alpha =0.0001:\", coeff_used00001)\n",
    "\n",
    "\n",
    "# alpha = 0.05\n",
    "# lasso00001 = Lasso(alpha=0.05, max_iter=10e5)\n",
    "# lasso00001.fit(X_train,y_train)\n",
    "\n",
    "# train_score00001=lasso00001.score(X_train,y_train)\n",
    "# test_score00001=lasso00001.score(X_test,y_test)\n",
    "\n",
    "# coeff_used00001 = np.sum(lasso00001.coef_!=0)\n",
    "\n",
    "# print(\"training score for alpha=0.05:\", train_score00001) \n",
    "# print(\"test score for alpha =0.05: \", test_score00001)\n",
    "# print(\"number of features used: for alpha =0.05:\", coeff_used00001)\n",
    "\n",
    "# alpha = 0.000001\n",
    "# lasso00001 = Lasso(alpha=0.000001, max_iter=10e5)\n",
    "# lasso00001.fit(X_train,y_train)\n",
    "\n",
    "# train_score00001=lasso00001.score(X_train,y_train)\n",
    "# test_score00001=lasso00001.score(X_test,y_test)\n",
    "\n",
    "# coeff_used00001 = np.sum(lasso00001.coef_!=0)\n",
    "\n",
    "# print(\"training score for alpha=0.000001:\", train_score00001) \n",
    "# print(\"test score for alpha =0.000001: \", test_score00001)\n",
    "# print(\"number of features used: for alpha =0.000001:\", coeff_used00001)\n",
    "\n",
    "y_pred = lasso00001.predict(X_test)\n",
    "print('Linear Regression R squared: %.4f' % lasso00001.score(X_test, y_test))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse = mean_squared_error(y_pred, y_test)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print('Linear Regression RMSE: %.4f' % lin_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
